{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Building a english to french translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "names=pd.read_csv('human_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.name=names.name.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=pd.DataFrame({'name':names.name.unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>william</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>james</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name\n",
       "0     john\n",
       "1  william\n",
       "2    james\n",
       "3  charles\n",
       "4   george"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenght_list=[]\n",
    "for l in names.name:\n",
    "    lenght_list.append(len(l))\n",
    "max_len = np.max(lenght_list)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append '\\t' to input to delay target by 1 timstamp\n",
    "names['name']=names.name.apply(lambda x:'\\t'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append \\n to notify end of word\n",
    "names['target']=names.name.apply(lambda x:x[1:len(x)]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6782, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocab dict\n",
    "all_chars=set()\n",
    "for name in names.name:\n",
    "    for c in name:\n",
    "        if c not in all_chars:\n",
    "            all_chars.add(c)\n",
    "all_chars.add('\\n')\n",
    "\n",
    "# max length of a name is 11\n",
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(all_chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(all_chars)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.zeros((len(names.name), max_len, 28),dtype='float32')\n",
    "output_data = np.zeros((len(names.name), max_len, 28),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input and output data\n",
    "for i, x in enumerate(names.name):\n",
    "    for t, ch in enumerate(x):\n",
    "        input_data[i, t, char_to_ix[ch]] = 1.\n",
    "for i, x in enumerate(names.target):\n",
    "    for t, ch in enumerate(x):\n",
    "        output_data[i,t, char_to_ix[ch]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shivam.prasad/Documents/virtual_envs/max/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(max_len, len(all_chars)), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(len(all_chars))))\n",
    "model.add(TimeDistributed(Activation('softmax')))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 12, 50)            15800     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 12, 28)            1428      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 12, 28)            0         \n",
      "=================================================================\n",
      "Total params: 17,228\n",
      "Trainable params: 17,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function to generate new names\n",
    "def onend(epoch, logs):\n",
    "    if epoch%2==0 and epoch !=0:\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "        for i in range(0,10):\n",
    "            stop=False\n",
    "            ch='\\t'\n",
    "            counter=1\n",
    "            target_seq = np.zeros((1, max_len, 28))\n",
    "            target_seq[0, 0, char_to_ix[ch]] = 1.\n",
    "            while stop == False and counter < 10:\n",
    "                #sample the data\n",
    "                probs = model.predict_proba(target_seq, verbose=0)[:,counter-1,:]\n",
    "                c= np.random.choice(sorted(list(all_chars)), replace =False,p=probs.reshape(28))\n",
    "                #c=ix_to_char[np.argmax(probs.reshape(28))]\n",
    "                if c=='\\n':\n",
    "                    stop=True\n",
    "                else:\n",
    "                    ch=ch+c\n",
    "                    target_seq[0,counter , char_to_ix[c]] = 1.\n",
    "                    counter=counter+1\n",
    "            print(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shivam.prasad/Documents/virtual_envs/max/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 6782 samples\n",
      "Epoch 1/20\n",
      "6782/6782 [==============================] - 2s 349us/sample - loss: 1.3665\n",
      "Epoch 2/20\n",
      "6782/6782 [==============================] - 2s 262us/sample - loss: 1.2411\n",
      "Epoch 3/20\n",
      "6560/6782 [============================>.] - ETA: 0s - loss: 1.2008----- Generating text after Epoch: 2\n",
      "\tbraellon\n",
      "\tlie\n",
      "\tdinelli\n",
      "\tmanerit\n",
      "\tmaltico\n",
      "\tmakha\n",
      "\tchlecesta\n",
      "\tkosdiah\n",
      "\tdabine\n",
      "\twadel\n",
      "6782/6782 [==============================] - 2s 305us/sample - loss: 1.2012\n",
      "Epoch 4/20\n",
      "6782/6782 [==============================] - 2s 277us/sample - loss: 1.1734\n",
      "Epoch 5/20\n",
      "6592/6782 [============================>.] - ETA: 0s - loss: 1.1505----- Generating text after Epoch: 4\n",
      "\tfertrel\n",
      "\travya\n",
      "\tbuetley\n",
      "\tchillus\n",
      "\tnamaam\n",
      "\tambee\n",
      "\tgeelme\n",
      "\tclaund\n",
      "\tbred\n",
      "\tliil\n",
      "6782/6782 [==============================] - 2s 298us/sample - loss: 1.1504\n",
      "Epoch 6/20\n",
      "6782/6782 [==============================] - 2s 272us/sample - loss: 1.1328\n",
      "Epoch 7/20\n",
      "6752/6782 [============================>.] - ETA: 0s - loss: 1.1169----- Generating text after Epoch: 6\n",
      "\ttamdia\n",
      "\tfradey\n",
      "\tlieley\n",
      "\tchents\n",
      "\tmaevaa\n",
      "\trayford\n",
      "\tomat\n",
      "\tsyda\n",
      "\tjose\n",
      "\tfary\n",
      "6782/6782 [==============================] - 2s 304us/sample - loss: 1.1170\n",
      "Epoch 8/20\n",
      "6782/6782 [==============================] - 2s 283us/sample - loss: 1.1041\n",
      "Epoch 9/20\n",
      "6656/6782 [============================>.] - ETA: 0s - loss: 1.0916----- Generating text after Epoch: 8\n",
      "\tnela\n",
      "\trowen\n",
      "\taudruyce\n",
      "\tbriona\n",
      "\tressel\n",
      "\tmalferden\n",
      "\tmillee\n",
      "\ttzedrick\n",
      "\talma\n",
      "\tdom\n",
      "6782/6782 [==============================] - 2s 320us/sample - loss: 1.0917\n",
      "Epoch 10/20\n",
      "6782/6782 [==============================] - 2s 284us/sample - loss: 1.0812\n",
      "Epoch 11/20\n",
      "6624/6782 [============================>.] - ETA: 0s - loss: 1.0723----- Generating text after Epoch: 10\n",
      "\telpine\n",
      "\tmarcine\n",
      "\tnigna\n",
      "\tlalence\n",
      "\taudrey\n",
      "\tbarry\n",
      "\tjaben\n",
      "\tsabym\n",
      "\tkimsta\n",
      "\taliber\n",
      "6782/6782 [==============================] - 2s 315us/sample - loss: 1.0720\n",
      "Epoch 12/20\n",
      "6782/6782 [==============================] - 2s 275us/sample - loss: 1.0639\n",
      "Epoch 13/20\n",
      "6624/6782 [============================>.] - ETA: 0s - loss: 1.0575----- Generating text after Epoch: 12\n",
      "\tluanette\n",
      "\tjeanah\n",
      "\telika\n",
      "\tcelina\n",
      "\tevion\n",
      "\tshanoy\n",
      "\tpennifo\n",
      "\tjilshia\n",
      "\tjessepham\n",
      "\tchristop\n",
      "6782/6782 [==============================] - 2s 325us/sample - loss: 1.0573\n",
      "Epoch 14/20\n",
      "6782/6782 [==============================] - 2s 258us/sample - loss: 1.0499\n",
      "Epoch 15/20\n",
      "6656/6782 [============================>.] - ETA: 0s - loss: 1.0433----- Generating text after Epoch: 14\n",
      "\tnonisa\n",
      "\tquiani\n",
      "\tkislie\n",
      "\tsavior\n",
      "\tjudy\n",
      "\tfandsor\n",
      "\tsofbin\n",
      "\tinelm\n",
      "\tarole\n",
      "\tlyn\n",
      "6782/6782 [==============================] - 2s 283us/sample - loss: 1.0432\n",
      "Epoch 16/20\n",
      "6782/6782 [==============================] - 2s 284us/sample - loss: 1.0384\n",
      "Epoch 17/20\n",
      "6624/6782 [============================>.] - ETA: 0s - loss: 1.0331----- Generating text after Epoch: 16\n",
      "\ttalie\n",
      "\ttimo\n",
      "\tmazubet\n",
      "\tmarlara\n",
      "\tarlean\n",
      "\tstudrel\n",
      "\tdemart\n",
      "\tdemi\n",
      "\tcariey\n",
      "\tglydde\n",
      "6782/6782 [==============================] - 2s 312us/sample - loss: 1.0332\n",
      "Epoch 18/20\n",
      "6782/6782 [==============================] - 2s 265us/sample - loss: 1.0296\n",
      "Epoch 19/20\n",
      "6560/6782 [============================>.] - ETA: 0s - loss: 1.0254----- Generating text after Epoch: 18\n",
      "\tlie\n",
      "\twilsiann\n",
      "\taddisha\n",
      "\teollene\n",
      "\tshievondr\n",
      "\tloven\n",
      "\tchryst\n",
      "\trhyant\n",
      "\tdayta\n",
      "\telesa\n",
      "6782/6782 [==============================] - 2s 279us/sample - loss: 1.0253\n",
      "Epoch 20/20\n",
      "6782/6782 [==============================] - 2s 253us/sample - loss: 1.0211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14b1bc350>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "try:\n",
    "    model.load('robert.hdf5')\n",
    "except:\n",
    "    print(\"No checkpoint available!\")\n",
    "    print_callback = LambdaCallback(on_epoch_end=onend)\n",
    "    model.fit(input_data, output_data, batch_size=32,epochs=20, callbacks=[print_callback])\n",
    "    model.save('robert.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tsentho\n",
      "\t\tdavis\n",
      "\t\ttawerl\n",
      "\t\tnayere\n",
      "\t\theylie\n",
      "\t\tjaylynn\n",
      "\t\tjanell\n",
      "\t\tvamarcus\n",
      "\t\tmarcelia\n",
      "\t\tnakory\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    stop=False\n",
    "    ch='\\t'\n",
    "    counter=1\n",
    "    target_seq = np.zeros((1, max_len, 28))\n",
    "    target_seq[0, 0, char_to_ix[ch]] = 1.\n",
    "    while stop == False and counter < 10:\n",
    "        #sample the data\n",
    "        probs = model.predict_proba(target_seq, verbose=0)[:,counter-1,:]\n",
    "        c= np.random.choice(sorted(list(all_chars)), replace =False,p=probs.reshape(28))\n",
    "        #c=ix_to_char[np.argmax(probs.reshape(28))]\n",
    "        if c=='\\n':\n",
    "            stop=True\n",
    "        else:\n",
    "            ch=ch+c\n",
    "            target_seq[0,counter , char_to_ix[c]] = 1.\n",
    "            counter=counter+1\n",
    "    print(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
