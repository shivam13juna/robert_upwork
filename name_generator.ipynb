{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Building a english to french translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "names=pd.read_csv('human_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.name=names.name.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=pd.DataFrame({'name':names.name.unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>william</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>james</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name\n",
       "0     john\n",
       "1  william\n",
       "2    james\n",
       "3  charles\n",
       "4   george"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenght_list=[]\n",
    "for l in names.name:\n",
    "    lenght_list.append(len(l))\n",
    "max_len = np.max(lenght_list)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append '\\t' to input to delay target by 1 timstamp\n",
    "names['name']=names.name.apply(lambda x:'\\t'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append \\n to notify end of word\n",
    "names['target']=names.name.apply(lambda x:x[1:len(x)]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6782, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocab dict\n",
    "all_chars=set()\n",
    "for name in names.name:\n",
    "    for c in name:\n",
    "        if c not in all_chars:\n",
    "            all_chars.add(c)\n",
    "all_chars.add('\\n')\n",
    "\n",
    "# max length of a name is 11\n",
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(all_chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(all_chars)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.zeros((len(names.name), max_len, 28),dtype='float32')\n",
    "output_data = np.zeros((len(names.name), max_len, 28),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input and output data\n",
    "for i, x in enumerate(names.name):\n",
    "    for t, ch in enumerate(x):\n",
    "        input_data[i, t, char_to_ix[ch]] = 1.\n",
    "for i, x in enumerate(names.target):\n",
    "    for t, ch in enumerate(x):\n",
    "        output_data[i,t, char_to_ix[ch]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(max_len, len(all_chars)), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(len(all_chars))))\n",
    "model.add(TimeDistributed(Activation('softmax')))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 13, 50)            15800     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 13, 28)            1428      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 13, 28)            0         \n",
      "=================================================================\n",
      "Total params: 17,228\n",
      "Trainable params: 17,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function to generate new names\n",
    "def onend(epoch, logs):\n",
    "    if epoch%2==0 and epoch !=0:\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "        for i in range(0,10):\n",
    "            stop=False\n",
    "            ch='\\t'\n",
    "            counter=1\n",
    "            target_seq = np.zeros((1, max_len, 28))\n",
    "            target_seq[0, 0, char_to_ix[ch]] = 1.\n",
    "            while stop == False and counter < 10:\n",
    "                #sample the data\n",
    "                probs = model.predict_proba(target_seq, verbose=0)[:,counter-1,:]\n",
    "                c= np.random.choice(sorted(list(all_chars)), replace =False,p=probs.reshape(28))\n",
    "                #c=ix_to_char[np.argmax(probs.reshape(28))]\n",
    "                if c=='\\n':\n",
    "                    stop=True\n",
    "                else:\n",
    "                    ch=ch+c\n",
    "                    target_seq[0,counter , char_to_ix[c]] = 1.\n",
    "                    counter=counter+1\n",
    "            print(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6782 samples\n",
      "Epoch 1/100\n",
      "6782/6782 [==============================] - 1s 99us/sample - loss: 1.0827\n",
      "Epoch 2/100\n",
      "6782/6782 [==============================] - 1s 116us/sample - loss: 1.0620\n",
      "Epoch 3/100\n",
      "6528/6782 [===========================>..] - ETA: 0s - loss: 1.0459----- Generating text after Epoch: 2\n",
      "\t\tcharlie\n",
      "\t\tbristie\n",
      "\t\tlel\n",
      "\t\tsena\n",
      "\t\talsie\n",
      "\t\teargelin\n",
      "\t\tfrana\n",
      "\t\tgabenta\n",
      "\t\thain\n",
      "\t\tmichurle\n",
      "6782/6782 [==============================] - 3s 429us/sample - loss: 1.0449\n",
      "Epoch 4/100\n",
      "6782/6782 [==============================] - 1s 104us/sample - loss: 1.0303\n",
      "Epoch 5/100\n",
      "6592/6782 [============================>.] - ETA: 0s - loss: 1.0176----- Generating text after Epoch: 4\n",
      "\t\tshaquan\n",
      "\t\ttol\n",
      "\t\tkatis\n",
      "\t\teramor\n",
      "\t\temaria\n",
      "\t\tmilphera\n",
      "\t\tisa\n",
      "\t\tlolita\n",
      "\t\thedring\n",
      "\t\tadiah\n",
      "6782/6782 [==============================] - 3s 444us/sample - loss: 1.0184\n",
      "Epoch 6/100\n",
      "6782/6782 [==============================] - 1s 106us/sample - loss: 1.0062\n",
      "Epoch 7/100\n",
      "6528/6782 [===========================>..] - ETA: 0s - loss: 0.9952----- Generating text after Epoch: 6\n",
      "\t\tayel\n",
      "\t\tlare\n",
      "\t\tforgan\n",
      "\t\treeto\n",
      "\t\tswenten\n",
      "\t\tcharelle\n",
      "\t\tluretta\n",
      "\t\tmarolia\n",
      "\t\taselinig\n",
      "\t\tfrancal\n",
      "6782/6782 [==============================] - 3s 455us/sample - loss: 0.9960\n",
      "Epoch 8/100\n",
      "6782/6782 [==============================] - 1s 107us/sample - loss: 0.9873\n",
      "Epoch 9/100\n",
      "6752/6782 [============================>.] - ETA: 0s - loss: 0.9802----- Generating text after Epoch: 8\n",
      "\t\tklys\n",
      "\t\terthe\n",
      "\t\tchenela\n",
      "\t\tkatilia\n",
      "\t\tjoud\n",
      "\t\tvingel\n",
      "\t\talvrah\n",
      "\t\twinfhret\n",
      "\t\tkiyber\n",
      "\t\tzandyah\n",
      "6782/6782 [==============================] - 3s 437us/sample - loss: 0.9802\n",
      "Epoch 10/100\n",
      "6782/6782 [==============================] - 1s 103us/sample - loss: 0.9728\n",
      "Epoch 11/100\n",
      "6560/6782 [============================>.] - ETA: 0s - loss: 0.9655----- Generating text after Epoch: 10\n",
      "\t\tskyran\n",
      "\t\tarlen\n",
      "\t\tcolinga\n",
      "\t\ttrizie\n",
      "\t\ttierya\n",
      "\t\tsadona\n",
      "\t\tcrpsa\n",
      "\t\tjanembel\n",
      "\t\tdiaina\n",
      "\t\tbaxton\n",
      "6782/6782 [==============================] - 3s 454us/sample - loss: 0.9660\n",
      "Epoch 12/100\n",
      "6782/6782 [==============================] - 1s 109us/sample - loss: 0.9600\n",
      "Epoch 13/100\n",
      "6464/6782 [===========================>..] - ETA: 0s - loss: 0.9546----- Generating text after Epoch: 12\n",
      "\t\tlilla\n",
      "\t\tdara\n",
      "\t\ttorri\n",
      "\t\tcolae\n",
      "\t\truscel\n",
      "\t\tronnie\n",
      "\t\tterrian\n",
      "\t\tsnekie\n",
      "\t\tchryvan\n",
      "\t\ttan\n",
      "6782/6782 [==============================] - 3s 409us/sample - loss: 0.9549\n",
      "Epoch 14/100\n",
      "6782/6782 [==============================] - 1s 115us/sample - loss: 0.9508\n",
      "Epoch 15/100\n",
      "6528/6782 [===========================>..] - ETA: 0s - loss: 0.9444----- Generating text after Epoch: 14\n",
      "\t\t\n",
      "\t\tmarisa\n",
      "\t\tmaroldro\n",
      "\t\tjamela\n",
      "\t\tank\n",
      "\t\tstainne\n",
      "\t\tholma\n",
      "\t\trebbie\n",
      "\t\tdia\n",
      "\t\trosita\n",
      "6782/6782 [==============================] - 3s 452us/sample - loss: 0.9461\n",
      "Epoch 16/100\n",
      "6782/6782 [==============================] - 1s 108us/sample - loss: 0.9421\n",
      "Epoch 17/100\n",
      "6400/6782 [===========================>..] - ETA: 0s - loss: 0.9370----- Generating text after Epoch: 16\n",
      "\t\tbronna\n",
      "\t\tjoanette\n",
      "\t\tbarden\n",
      "\t\tbertina\n",
      "\t\tmarwil\n",
      "\t\tdenor\n",
      "\t\tfryce\n",
      "\t\tanjea\n",
      "\t\tvernetta\n",
      "\t\tlyne\n",
      "6782/6782 [==============================] - 3s 445us/sample - loss: 0.9385\n",
      "Epoch 18/100\n",
      "6782/6782 [==============================] - 1s 127us/sample - loss: 0.9358\n",
      "Epoch 19/100\n",
      "6528/6782 [===========================>..] - ETA: 0s - loss: 0.9311----- Generating text after Epoch: 18\n",
      "\t\tmark\n",
      "\t\tnicelas\n",
      "\t\tflishand\n",
      "\t\tshawna\n",
      "\t\tlinda\n",
      "\t\tcorroen\n",
      "\t\talijah\n",
      "\t\tjhandy\n",
      "\t\tina\n",
      "\t\tlaelen\n",
      "6782/6782 [==============================] - 3s 462us/sample - loss: 0.9316\n",
      "Epoch 20/100\n",
      "6782/6782 [==============================] - 1s 128us/sample - loss: 0.9294\n",
      "Epoch 21/100\n",
      "6560/6782 [============================>.] - ETA: 0s - loss: 0.9260----- Generating text after Epoch: 20\n",
      "\t\telisson\n",
      "\t\tardice\n",
      "\t\tallyn\n",
      "\t\tangellet\n",
      "\t\tluca\n",
      "\t\tken\n",
      "\t\tcisiana\n",
      "\t\tangelle\n",
      "\t\tisali\n",
      "\t\tyarely\n",
      "6782/6782 [==============================] - 4s 592us/sample - loss: 0.9265\n",
      "Epoch 22/100\n",
      "6782/6782 [==============================] - 1s 146us/sample - loss: 0.9231\n",
      "Epoch 23/100\n",
      "6400/6782 [===========================>..] - ETA: 0s - loss: 0.9218----- Generating text after Epoch: 22\n",
      "\t\tmernie\n",
      "\t\tgrianca\n",
      "\t\tjadi\n",
      "\t\tshaunon\n",
      "\t\tjenely\n",
      "\t\tdonnard\n",
      "\t\tdolloy\n",
      "\t\tkenney\n",
      "\t\ttyron\n",
      "\t\tbrent\n",
      "6782/6782 [==============================] - 4s 525us/sample - loss: 0.9220\n",
      "Epoch 24/100\n",
      "6782/6782 [==============================] - 1s 157us/sample - loss: 0.9188\n",
      "Epoch 25/100\n",
      "6432/6782 [===========================>..] - ETA: 0s - loss: 0.9150----- Generating text after Epoch: 24\n",
      "\t\tzaida\n",
      "\t\troderio\n",
      "\t\tyvitha\n",
      "\t\ttaya\n",
      "\t\ttohnna\n",
      "\t\tarvin\n",
      "\t\tdarrien\n",
      "\t\ttaya\n",
      "\t\tryler\n",
      "\t\tkeryl\n",
      "6782/6782 [==============================] - 4s 615us/sample - loss: 0.9166\n",
      "Epoch 26/100\n",
      "6782/6782 [==============================] - 1s 153us/sample - loss: 0.9146\n",
      "Epoch 27/100\n",
      "6560/6782 [============================>.] - ETA: 0s - loss: 0.9124----- Generating text after Epoch: 26\n",
      "\t\tjerrid\n",
      "\t\teannid\n",
      "\t\tlezal\n",
      "\t\talisha\n",
      "\t\tshapnos\n",
      "\t\tjoseferz\n",
      "\t\tjeman\n",
      "\t\tmargarit\n",
      "\t\tverelia\n",
      "\t\tcprronso\n",
      "6782/6782 [==============================] - 4s 606us/sample - loss: 0.9125\n",
      "Epoch 28/100\n",
      "6782/6782 [==============================] - 1s 166us/sample - loss: 0.9111\n",
      "Epoch 29/100\n",
      "6752/6782 [============================>.] - ETA: 0s - loss: 0.9088----- Generating text after Epoch: 28\n",
      "\t\tdorophy\n",
      "\t\tmariul\n",
      "\t\tdelmae\n",
      "\t\tsinton\n",
      "\t\thassugh\n",
      "\t\tmabal\n",
      "\t\tdelena\n",
      "\t\tjeora\n",
      "\t\tjulia\n",
      "\t\tdestina\n",
      "6782/6782 [==============================] - 4s 523us/sample - loss: 0.9090\n",
      "Epoch 30/100\n",
      "6782/6782 [==============================] - 1s 138us/sample - loss: 0.9073\n",
      "Epoch 31/100\n",
      "6592/6782 [============================>.] - ETA: 0s - loss: 0.9059----- Generating text after Epoch: 30\n",
      "\t\tkimrek\n",
      "\t\tmaritha\n",
      "\t\tmarisalo\n",
      "\t\tkathi\n",
      "\t\tjeryl\n",
      "\t\teola\n",
      "\t\tsidelia\n",
      "\t\tzadgar\n",
      "\t\taleyn\n",
      "\t\thilda\n",
      "6782/6782 [==============================] - 3s 497us/sample - loss: 0.9060\n",
      "Epoch 32/100\n",
      "6782/6782 [==============================] - 1s 137us/sample - loss: 0.9042\n",
      "Epoch 33/100\n",
      "6496/6782 [===========================>..] - ETA: 0s - loss: 0.9028----- Generating text after Epoch: 32\n",
      "\t\techane\n",
      "\t\tgayla\n",
      "\t\tpatrurd\n",
      "\t\tkenman\n",
      "\t\tkadice\n",
      "\t\tcyncie\n",
      "\t\tdarcell\n",
      "\t\tjaylen\n",
      "\t\tjordi\n",
      "\t\tcarri\n",
      "6782/6782 [==============================] - 3s 506us/sample - loss: 0.9026\n",
      "Epoch 34/100\n",
      "6782/6782 [==============================] - 1s 113us/sample - loss: 0.9019\n",
      "Epoch 35/100\n",
      "6464/6782 [===========================>..] - ETA: 0s - loss: 0.9013----- Generating text after Epoch: 34\n",
      "\t\tkathi\n",
      "\t\tdaraina\n",
      "\t\twinwor\n",
      "\t\talex\n",
      "\t\tdora\n",
      "\t\tantonett\n",
      "\t\tbenmy\n",
      "\t\tbirthie\n",
      "\t\tsseanon\n",
      "\t\tkora\n",
      "6782/6782 [==============================] - 3s 413us/sample - loss: 0.9009\n",
      "Epoch 36/100\n",
      "6782/6782 [==============================] - 1s 118us/sample - loss: 0.8989\n",
      "Epoch 37/100\n",
      "6592/6782 [============================>.] - ETA: 0s - loss: 0.8977----- Generating text after Epoch: 36\n",
      "\t\tmikarle\n",
      "\t\tadd\n",
      "\t\tjulianna\n",
      "\t\tcorid\n",
      "\t\tcarlyn\n",
      "\t\tjaculina\n",
      "\t\tamire\n",
      "\t\tdor\n",
      "\t\ttyran\n",
      "\t\tjachalyn\n",
      "6782/6782 [==============================] - 3s 414us/sample - loss: 0.8978\n",
      "Epoch 38/100\n",
      "6782/6782 [==============================] - 1s 112us/sample - loss: 0.8958\n",
      "Epoch 39/100\n",
      "6752/6782 [============================>.] - ETA: 0s - loss: 0.8961----- Generating text after Epoch: 38\n",
      "\t\tduster\n",
      "\t\tmilas\n",
      "\t\tcorila\n",
      "\t\tmarlee\n",
      "\t\tkathary\n",
      "\t\torvil\n",
      "\t\tandres\n",
      "\t\tcharley\n",
      "\t\tfrude\n",
      "\t\temilie\n",
      "6782/6782 [==============================] - 3s 422us/sample - loss: 0.8960\n",
      "Epoch 40/100\n",
      "6782/6782 [==============================] - 1s 113us/sample - loss: 0.8948\n",
      "Epoch 41/100\n",
      "6656/6782 [============================>.] - ETA: 0s - loss: 0.8943----- Generating text after Epoch: 40\n",
      "\t\ttaya\n",
      "\t\tlaison\n",
      "\t\tcarmo\n",
      "\t\taurorma\n",
      "\t\tmarlene\n",
      "\t\tjille\n",
      "\t\ttanika\n",
      "\t\tmina\n",
      "\t\thaymen\n",
      "\t\tnickoly\n",
      "6782/6782 [==============================] - 3s 498us/sample - loss: 0.8942\n",
      "Epoch 42/100\n",
      "6782/6782 [==============================] - 1s 123us/sample - loss: 0.8924\n",
      "Epoch 43/100\n",
      "6464/6782 [===========================>..] - ETA: 0s - loss: 0.8916----- Generating text after Epoch: 42\n",
      "\t\tearrelyn\n",
      "\t\trahurn\n",
      "\t\tdianna\n",
      "\t\tperry\n",
      "\t\truine\n",
      "\t\tkenzie\n",
      "\t\tgissie\n",
      "\t\tjamari\n",
      "\t\tgusticis\n",
      "\t\tmalfondi\n",
      "6782/6782 [==============================] - 3s 467us/sample - loss: 0.8920\n",
      "Epoch 44/100\n",
      "6782/6782 [==============================] - 1s 121us/sample - loss: 0.8909\n",
      "Epoch 45/100\n",
      "6592/6782 [============================>.] - ETA: 0s - loss: 0.8898----- Generating text after Epoch: 44\n",
      "\t\tcariene\n",
      "\t\tkathelyn\n",
      "\t\tlyda\n",
      "\t\tgicy\n",
      "\t\tlilliann\n",
      "\t\tteazai\n",
      "\t\tevanne\n",
      "\t\tjohnetta\n",
      "\t\tkarline\n",
      "\t\taugustin\n",
      "6782/6782 [==============================] - 3s 480us/sample - loss: 0.8903\n",
      "Epoch 46/100\n",
      "6782/6782 [==============================] - 1s 145us/sample - loss: 0.8892\n",
      "Epoch 47/100\n",
      "6752/6782 [============================>.] - ETA: 0s - loss: 0.8873----- Generating text after Epoch: 46\n",
      "\t\tbrien\n",
      "\t\tedmand\n",
      "\t\tashlyn\n",
      "\t\tlusa\n",
      "\t\tdalton\n",
      "\t\tstedelia\n",
      "\t\tennilde\n",
      "\t\tchen\n",
      "\t\tzada\n",
      "\t\tgregorie\n",
      "6782/6782 [==============================] - 4s 548us/sample - loss: 0.8872\n",
      "Epoch 48/100\n",
      "6782/6782 [==============================] - 1s 150us/sample - loss: 0.8863\n",
      "Epoch 49/100\n",
      "6432/6782 [===========================>..] - ETA: 0s - loss: 0.8853----- Generating text after Epoch: 48\n",
      "\t\tyuarff\n",
      "\t\tartayn\n",
      "\t\teugenes\n",
      "\t\thasta\n",
      "\t\tgilberte\n",
      "\t\thellie\n",
      "\t\tscprd\n",
      "\t\tdolton\n",
      "\t\tshelia\n",
      "\t\tnoroly\n",
      "6782/6782 [==============================] - 3s 504us/sample - loss: 0.8858\n",
      "Epoch 50/100\n",
      "6782/6782 [==============================] - 1s 109us/sample - loss: 0.8863\n",
      "Epoch 51/100\n",
      "6752/6782 [============================>.] - ETA: 0s - loss: 0.8843----- Generating text after Epoch: 50\n",
      "\t\tbrianda\n",
      "\t\tort\n",
      "\t\tamani\n",
      "\t\tdaisha\n",
      "\t\tverani\n",
      "\t\taugusten\n",
      "\t\tadison\n",
      "\t\telane\n",
      "\t\twestley\n",
      "\t\ttristonf\n",
      "6782/6782 [==============================] - 4s 527us/sample - loss: 0.8843\n",
      "Epoch 52/100\n",
      "6782/6782 [==============================] - 1s 149us/sample - loss: 0.8837\n",
      "Epoch 53/100\n",
      "6560/6782 [============================>.] - ETA: 0s - loss: 0.8821----- Generating text after Epoch: 52\n",
      "\t\tvelia\n",
      "\t\tcarrolne\n",
      "\t\tlilla\n",
      "\t\tilour\n",
      "\t\tmariena\n",
      "\t\trosmyn\n",
      "\t\tharry\n",
      "\t\tvarie\n",
      "\t\tkindy\n",
      "\t\tvalleey\n",
      "6782/6782 [==============================] - 4s 589us/sample - loss: 0.8825\n",
      "Epoch 54/100\n",
      "6782/6782 [==============================] - 1s 137us/sample - loss: 0.8820\n",
      "Epoch 55/100\n",
      "6624/6782 [============================>.] - ETA: 0s - loss: 0.8808----- Generating text after Epoch: 54\n",
      "\t\tmaun\n",
      "\t\tomar\n",
      "\t\tranda\n",
      "\t\tkenndon\n",
      "\t\twilston\n",
      "\t\tbetty\n",
      "\t\tdebbaney\n",
      "\t\tgarlee\n",
      "\t\tdoko\n",
      "\t\tdani\n",
      "6782/6782 [==============================] - 3s 444us/sample - loss: 0.8815\n",
      "Epoch 56/100\n",
      "6782/6782 [==============================] - 1s 139us/sample - loss: 0.8805\n",
      "Epoch 57/100\n",
      "6624/6782 [============================>.] - ETA: 0s - loss: 0.8812----- Generating text after Epoch: 56\n",
      "\t\thelsina\n",
      "\t\tkine\n",
      "\t\trewan\n",
      "\t\tabethe\n",
      "\t\tormond\n",
      "\t\tsumner\n",
      "\t\tvalarie\n",
      "\t\tbrandie\n",
      "\t\ttalen\n",
      "\t\tgamie\n",
      "6782/6782 [==============================] - 3s 480us/sample - loss: 0.8815\n",
      "Epoch 58/100\n",
      "6782/6782 [==============================] - 1s 121us/sample - loss: 0.8800\n",
      "Epoch 59/100\n",
      "6592/6782 [============================>.] - ETA: 0s - loss: 0.8803----- Generating text after Epoch: 58\n",
      "\t\tdeenael\n",
      "\t\tdamaris\n",
      "\t\tdarrin\n",
      "\t\telo\n",
      "\t\tnaolet\n",
      "\t\tsabert\n",
      "\t\trubie\n",
      "\t\tseja\n",
      "\t\tparriett\n",
      "\t\telyn\n",
      "6782/6782 [==============================] - 3s 432us/sample - loss: 0.8801\n",
      "Epoch 60/100\n",
      "6782/6782 [==============================] - 1s 135us/sample - loss: 0.8793\n",
      "Epoch 61/100\n",
      "6528/6782 [===========================>..] - ETA: 0s - loss: 0.8784----- Generating text after Epoch: 60\n",
      "\t\tmartine\n",
      "\t\tjame\n",
      "\t\tmampios\n",
      "\t\tkath\n",
      "\t\terich\n",
      "\t\tfloryn\n",
      "\t\tmeody\n",
      "\t\tkault\n",
      "\t\tnie\n",
      "\t\tpenesie\n",
      "6782/6782 [==============================] - 3s 457us/sample - loss: 0.8782\n",
      "Epoch 62/100\n",
      "6782/6782 [==============================] - 1s 138us/sample - loss: 0.8781\n",
      "Epoch 63/100\n",
      "6528/6782 [===========================>..] - ETA: 0s - loss: 0.8759----- Generating text after Epoch: 62\n",
      "\t\tlessie\n",
      "\t\tedeso\n",
      "\t\tsheylius\n",
      "\t\teelina\n",
      "\t\tbossee\n",
      "\t\tscospenn\n",
      "\t\trandel\n",
      "\t\tnie\n",
      "\t\teugan\n",
      "\t\tbois\n",
      "6782/6782 [==============================] - 3s 456us/sample - loss: 0.8766\n",
      "Epoch 64/100\n",
      "6782/6782 [==============================] - 1s 131us/sample - loss: 0.8769\n",
      "Epoch 65/100\n",
      "6368/6782 [===========================>..] - ETA: 0s - loss: 0.8746----- Generating text after Epoch: 64\n",
      "\t\tsheryn\n",
      "\t\twilhelmo\n",
      "\t\tsamira\n",
      "\t\tbezer\n",
      "\t\tbercell\n",
      "\t\tchermane\n",
      "\t\tpeto\n",
      "\t\tirdus\n",
      "\t\thoston\n",
      "\t\talbert\n",
      "6782/6782 [==============================] - 3s 430us/sample - loss: 0.8758\n",
      "Epoch 66/100\n",
      "6782/6782 [==============================] - 1s 121us/sample - loss: 0.8760\n",
      "Epoch 67/100\n",
      "6720/6782 [============================>.] - ETA: 0s - loss: 0.8751----- Generating text after Epoch: 66\n",
      "\t\tcecie\n",
      "\t\tverson\n",
      "\t\tyudetri\n",
      "\t\tgilfon\n",
      "\t\tlillyr\n",
      "\t\tmaly\n",
      "\t\tlimmie\n",
      "\t\tmariah\n",
      "\t\tmegan\n",
      "\t\trody\n",
      "6782/6782 [==============================] - 4s 520us/sample - loss: 0.8752\n",
      "Epoch 68/100\n",
      "6782/6782 [==============================] - 1s 134us/sample - loss: 0.8750\n",
      "Epoch 69/100\n",
      "6304/6782 [==========================>...] - ETA: 0s - loss: 0.8742----- Generating text after Epoch: 68\n",
      "\t\tharry\n",
      "\t\tcheanus\n",
      "\t\tloba\n",
      "\t\tflorylyn\n",
      "\t\tmefrache\n",
      "\t\tarlene\n",
      "\t\tmadelee\n",
      "\t\tcarloy\n",
      "\t\tmarvel\n",
      "\t\tshado\n",
      "6782/6782 [==============================] - 3s 429us/sample - loss: 0.8752\n",
      "Epoch 70/100\n",
      "6782/6782 [==============================] - 1s 131us/sample - loss: 0.8738\n",
      "Epoch 71/100\n",
      "6720/6782 [============================>.] - ETA: 0s - loss: 0.8727----- Generating text after Epoch: 70\n",
      "\t\tmargone\n",
      "\t\tshellan\n",
      "\t\tdelpho\n",
      "\t\tderill\n",
      "\t\ttimmer\n",
      "\t\tbettie\n",
      "\t\tmarianna\n",
      "\t\tkimbierc\n",
      "\t\tjoha\n",
      "\t\tsharue\n",
      "6782/6782 [==============================] - 3s 457us/sample - loss: 0.8730\n",
      "Epoch 72/100\n",
      "6782/6782 [==============================] - 1s 120us/sample - loss: 0.8737\n",
      "Epoch 73/100\n",
      "6624/6782 [============================>.] - ETA: 0s - loss: 0.8722----- Generating text after Epoch: 72\n",
      "\t\tbenice\n",
      "\t\tsakeer\n",
      "\t\tlevin\n",
      "\t\tlana\n",
      "\t\tcollard\n",
      "\t\tconsonne\n",
      "\t\tkarlene\n",
      "\t\tmornallo\n",
      "\t\talene\n",
      "\t\tgreta\n",
      "6782/6782 [==============================] - 3s 432us/sample - loss: 0.8727\n",
      "Epoch 74/100\n",
      "6782/6782 [==============================] - 1s 113us/sample - loss: 0.8732\n",
      "Epoch 75/100\n",
      "6752/6782 [============================>.] - ETA: 0s - loss: 0.8709----- Generating text after Epoch: 74\n",
      "\t\tjornie\n",
      "\t\tagvon\n",
      "\t\tjalen\n",
      "\t\tshemire\n",
      "\t\tcorman\n",
      "\t\topie\n",
      "\t\tzassin\n",
      "\t\tstaifie\n",
      "\t\tmilah\n",
      "\t\trilyn\n",
      "6782/6782 [==============================] - 3s 425us/sample - loss: 0.8709\n",
      "Epoch 76/100\n",
      "6782/6782 [==============================] - 1s 123us/sample - loss: 0.8724\n",
      "Epoch 77/100\n",
      "6528/6782 [===========================>..] - ETA: 0s - loss: 0.8704----- Generating text after Epoch: 76\n",
      "\t\tjaneon\n",
      "\t\twylie\n",
      "\t\tsydell\n",
      "\t\talexa\n",
      "\t\tclarence\n",
      "\t\tarnie\n",
      "\t\tkaylah\n",
      "\t\tjenni\n",
      "\t\tdiacha\n",
      "\t\tburk\n",
      "6782/6782 [==============================] - 3s 451us/sample - loss: 0.8713\n",
      "Epoch 78/100\n",
      "6782/6782 [==============================] - 1s 122us/sample - loss: 0.8718\n",
      "Epoch 79/100\n",
      "6464/6782 [===========================>..] - ETA: 0s - loss: 0.8707----- Generating text after Epoch: 78\n",
      "\t\tdarleen\n",
      "\t\tfarnetta\n",
      "\t\traymond\n",
      "\t\tcarrol\n",
      "\t\ttamie\n",
      "\t\tnikor\n",
      "\t\tjuliya\n",
      "\t\taivon\n",
      "\t\tevie\n",
      "\t\tfibine\n",
      "6782/6782 [==============================] - 3s 447us/sample - loss: 0.8705\n",
      "Epoch 80/100\n",
      "6782/6782 [==============================] - 1s 141us/sample - loss: 0.8702\n",
      "Epoch 81/100\n",
      "6688/6782 [============================>.] - ETA: 0s - loss: 0.8686----- Generating text after Epoch: 80\n",
      "\t\tkatyline\n",
      "\t\tpaarline\n",
      "\t\tdebby\n",
      "\t\tmalee\n",
      "\t\tolive\n",
      "\t\tverna\n",
      "\t\tsanay\n",
      "\t\toqueni\n",
      "\t\tcaidy\n",
      "\t\trubi\n",
      "6782/6782 [==============================] - 3s 477us/sample - loss: 0.8692\n",
      "Epoch 82/100\n",
      "6782/6782 [==============================] - 1s 118us/sample - loss: 0.8705\n",
      "Epoch 83/100\n",
      "6368/6782 [===========================>..] - ETA: 0s - loss: 0.8691----- Generating text after Epoch: 82\n",
      "\t\tshaquill\n",
      "\t\tgwinth\n",
      "\t\tariel\n",
      "\t\tmichelle\n",
      "\t\temelia\n",
      "\t\tblara\n",
      "\t\trisa\n",
      "\t\tadrill\n",
      "\t\tdorotha\n",
      "\t\tarlena\n",
      "6782/6782 [==============================] - 4s 569us/sample - loss: 0.8694\n",
      "Epoch 84/100\n",
      "6782/6782 [==============================] - 1s 137us/sample - loss: 0.8685\n",
      "Epoch 85/100\n",
      "6752/6782 [============================>.] - ETA: 0s - loss: 0.8689----- Generating text after Epoch: 84\n",
      "\t\tdanidana\n",
      "\t\tivine\n",
      "\t\tvergil\n",
      "\t\tvella\n",
      "\t\thottie\n",
      "\t\tshon\n",
      "\t\tshephren\n",
      "\t\thelma\n",
      "\t\tjanetta\n",
      "\t\tgennio\n",
      "6782/6782 [==============================] - 3s 424us/sample - loss: 0.8690\n",
      "Epoch 86/100\n",
      "6782/6782 [==============================] - 1s 139us/sample - loss: 0.8684\n",
      "Epoch 87/100\n",
      "6496/6782 [===========================>..] - ETA: 0s - loss: 0.8672----- Generating text after Epoch: 86\n",
      "\t\tgnooson\n",
      "\t\tdianne\n",
      "\t\tklota\n",
      "\t\twayland\n",
      "\t\tkalotha\n",
      "\t\tabdalile\n",
      "\t\thilaiso\n",
      "\t\tanula\n",
      "\t\tanner\n",
      "\t\tmattie\n",
      "6782/6782 [==============================] - 3s 484us/sample - loss: 0.8677\n",
      "Epoch 88/100\n",
      "6782/6782 [==============================] - 1s 117us/sample - loss: 0.8673\n",
      "Epoch 89/100\n",
      "6432/6782 [===========================>..] - ETA: 0s - loss: 0.8667----- Generating text after Epoch: 88\n",
      "\t\tpavella\n",
      "\t\tblancee\n",
      "\t\tbrittnie\n",
      "\t\thobey\n",
      "\t\tverlyn\n",
      "\t\tkelsie\n",
      "\t\tfelitha\n",
      "\t\tdonovan\n",
      "\t\tdoree\n",
      "\t\tharle\n",
      "6782/6782 [==============================] - 3s 468us/sample - loss: 0.8673\n",
      "Epoch 90/100\n",
      "6782/6782 [==============================] - 1s 121us/sample - loss: 0.8673\n",
      "Epoch 91/100\n",
      "6592/6782 [============================>.] - ETA: 0s - loss: 0.8662----- Generating text after Epoch: 90\n",
      "\t\tmacee\n",
      "\t\tgante\n",
      "\t\tisha\n",
      "\t\tcarey\n",
      "\t\tkemmie\n",
      "\t\tgerry\n",
      "\t\tscottin\n",
      "\t\trhando\n",
      "\t\ttyrell\n",
      "\t\tfloren\n",
      "6782/6782 [==============================] - 3s 495us/sample - loss: 0.8658\n",
      "Epoch 92/100\n",
      "6782/6782 [==============================] - 1s 124us/sample - loss: 0.8662\n",
      "Epoch 93/100\n",
      "6336/6782 [===========================>..] - ETA: 0s - loss: 0.8663----- Generating text after Epoch: 92\n",
      "\t\tvician\n",
      "\t\tstoneh\n",
      "\t\tanolah\n",
      "\t\tmillis\n",
      "\t\tcfreris\n",
      "\t\tlevin\n",
      "\t\tlucier\n",
      "\t\tmagdaly\n",
      "\t\tgeriah\n",
      "\t\tirvin\n",
      "6782/6782 [==============================] - 3s 482us/sample - loss: 0.8664\n",
      "Epoch 94/100\n",
      "6782/6782 [==============================] - 1s 139us/sample - loss: 0.8659\n",
      "Epoch 95/100\n",
      "6464/6782 [===========================>..] - ETA: 0s - loss: 0.8644----- Generating text after Epoch: 94\n",
      "\t\tlandi\n",
      "\t\ttatsan\n",
      "\t\tcerlann\n",
      "\t\talline\n",
      "\t\tdonte\n",
      "\t\tcorine\n",
      "\t\tlatoyain\n",
      "\t\tlora\n",
      "\t\tharley\n",
      "\t\tdavey\n",
      "6782/6782 [==============================] - 3s 505us/sample - loss: 0.8645\n",
      "Epoch 96/100\n",
      "6782/6782 [==============================] - 1s 130us/sample - loss: 0.8656\n",
      "Epoch 97/100\n",
      "6560/6782 [============================>.] - ETA: 0s - loss: 0.8649----- Generating text after Epoch: 96\n",
      "\t\terry\n",
      "\t\tsibbie\n",
      "\t\tasslio\n",
      "\t\tbrant\n",
      "\t\tjoseph\n",
      "\t\ttandy\n",
      "\t\trettey\n",
      "\t\tive\n",
      "\t\tcarsil\n",
      "\t\tautrid\n",
      "6782/6782 [==============================] - 3s 478us/sample - loss: 0.8650\n",
      "Epoch 98/100\n",
      "6782/6782 [==============================] - 1s 162us/sample - loss: 0.8648\n",
      "Epoch 99/100\n",
      "6496/6782 [===========================>..] - ETA: 0s - loss: 0.8641----- Generating text after Epoch: 98\n",
      "\t\tvernette\n",
      "\t\tmaxim\n",
      "\t\tjoquenci\n",
      "\t\tknaxceth\n",
      "\t\tdeora\n",
      "\t\twamford\n",
      "\t\tshanita\n",
      "\t\tchlayne\n",
      "\t\tyosey\n",
      "\t\tlucio\n",
      "6782/6782 [==============================] - 4s 528us/sample - loss: 0.8640\n",
      "Epoch 100/100\n",
      "6782/6782 [==============================] - 1s 160us/sample - loss: 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc9fde8c470>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "print_callback = LambdaCallback(on_epoch_end=onend)\n",
    "model.fit(input_data, output_data, batch_size=32,epochs=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tsentho\n",
      "\t\tdavis\n",
      "\t\ttawerl\n",
      "\t\tnayere\n",
      "\t\theylie\n",
      "\t\tjaylynn\n",
      "\t\tjanell\n",
      "\t\tvamarcus\n",
      "\t\tmarcelia\n",
      "\t\tnakory\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    stop=False\n",
    "    ch='\\t'\n",
    "    counter=1\n",
    "    target_seq = np.zeros((1, max_len, 28))\n",
    "    target_seq[0, 0, char_to_ix[ch]] = 1.\n",
    "    while stop == False and counter < 10:\n",
    "        #sample the data\n",
    "        probs = model.predict_proba(target_seq, verbose=0)[:,counter-1,:]\n",
    "        c= np.random.choice(sorted(list(all_chars)), replace =False,p=probs.reshape(28))\n",
    "        #c=ix_to_char[np.argmax(probs.reshape(28))]\n",
    "        if c=='\\n':\n",
    "            stop=True\n",
    "        else:\n",
    "            ch=ch+c\n",
    "            target_seq[0,counter , char_to_ix[c]] = 1.\n",
    "            counter=counter+1\n",
    "    print(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
